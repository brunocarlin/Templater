---
title: "skeleton"
author: "Bruno Carlin"
date: "07/07/2018"
output:
  html_document:
    toc: true # table of content true
    toc_depth: 3  # upto three depths of headings (specified by #, ## and ###)
    number_sections: true  ## if you want number sections at each table header
    theme: united  # many options for theme, this one is my favorite.
    highlight: tango  # specifies the syntax highlighting style
---

# Importing the libraries
```{r setup, include=FALSE}
knitr::opts_knit$set(root.dir = normalizePath("~/TCC/R/Krill-Machine-Learning/Machine Learning A-Z Template Folder/Part 1 - Data Preprocessing/Data_Preprocessing"))
```

```{r R Library}
library(reticulate)
library(caTools)
set.seed(123)
```


```{python Pythom Library}
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import os
os.environ['QT_QPA_PLATFORM_PLUGIN_PATH'] = '/Users/Anton/Anaconda3/Library/plugins/platforms'
```

```


# Python

## Importing the dataset

```{python}
dataset = pd.read_csv('Data.csv')
X = dataset.iloc[:, :-1].values
y = dataset.iloc[:, 3].values
```

## Splitting the dataset into the Training set and Test set
```{python}
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)
```


```{python eval=FALSE, include=FALSE}
# Feature Scaling
"""from sklearn.preprocessing import StandardScaler
sc_X = StandardScaler()
X_train = sc_X.fit_transform(X_train)
X_test = sc_X.transform(X_test)
sc_y = StandardScaler()
y_train = sc_y.fit_transform(y_train)"""
```



# R

## Importing the dataset

```{r}
dataset = read.csv('Data.csv')
```

## Splitting the dataset into the Training set and Test set



```{r}
library(caTools)
set.seed(123)
split = sample.split(dataset$DependantVariable, SplitRatio = 0.8)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
```


```{r eval=FALSE, include=FALSE}
# Feature Scaling
# training_set = scale(training_set)
# test_set = scale(test_set)
```


